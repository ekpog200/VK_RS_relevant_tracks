{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a3f658-332c-47a6-9c32-c731134fba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2cc2b2-d308-4e8d-b246-23ca4eb198ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(dataset):\n",
    "    '''Generating features: a time feature, user & song profile features, and SVD features\n",
    "    Args:\n",
    "        dataset: a pandas.DataFrame that has been preprocessed\n",
    "    Return:\n",
    "        a pandas.DataFrame of processed data\n",
    "    '''\n",
    "    ### timestamp feature\n",
    "    dataset['seq_time'] = np.arange(dataset.shape[0], dtype=np.float32)\n",
    "    \n",
    "    # функция генерирует профильные признаки на основе идентификатора пользователя или песни (item).\n",
    "    # Признаки включают статистические характеристики, такие как среднее и стандартное отклонение для непрерывных переменных \n",
    "    # continuous_vars и отношение частот для категориальных переменных category_vars.\n",
    "    def create_profile(item, continuous_vars, category_vars):\n",
    "        dataframes_profile = pd.DataFrame({item: dataset[item], item + '_count': dataset.groupby(item)[item].transform('count')})\n",
    "        for featur in continuous_vars:\n",
    "            dataframes_profile[item + '_' + featur + '_mean'] = dataset.groupby(item)[featur].transform('mean')\n",
    "            dataframes_profile.loc[:, item + '_' + featur + '_std'] = dataset.groupby(item)[featur].transform('std')\n",
    "        for featur in category_vars:\n",
    "            dataframes_profile[item + '_' + featur + '_ratio'] = dataset.groupby([item, featur])[featur].transform('count')/dataframes_profile[item+'_count']\n",
    "        for col in dataframes_profile.columns:\n",
    "            if col != item:\n",
    "                dataframes_profile[col] = dataframes_profile[col].astype('float32')\n",
    "        return dataframes_profile\n",
    "    \n",
    "    \n",
    "    # user profile\n",
    "    item = 'msno'\n",
    "    continuous_vars = ['song_length']\n",
    "    category_vars = ['genre_ids', 'language', 'registered_via', 'source_screen_name', 'source_system_tab', 'source_type']\n",
    "    dataset_profile_msno = create_profile(item, continuous_vars, category_vars)\n",
    "\n",
    "    # song profile\n",
    "    item = 'song_id'\n",
    "    continuous_vars = ['bd', 'expiration_date', 'register_period', 'registration_init_time']\n",
    "    category_vars = ['city', 'gender', 'registered_via', 'source_screen_name', 'source_system_tab', 'source_type']\n",
    "    dataframe_profile_song_id = create_profile(item, continuous_vars, category_vars)\n",
    "    \n",
    "    ### get latent features\n",
    "    # counts concurrence\n",
    "    dataframes_latents = dataset[['msno', 'song_id', 'artist_name']]\n",
    "    dataframes_latents['times_song_id'] = dataframes_latents.groupby(['msno', 'song_id'])['msno'].transform('count')\n",
    "    dataframes_latents['times_artist_name'] = dataframes_latents.groupby(['msno', 'artist_name'])['msno'].transform('count')\n",
    "\n",
    "    # map index\n",
    "    all_msno = sorted(dataframes_latents['msno'].unique())\n",
    "    all_msno = dict(zip(all_msno, range(len(all_msno))))\n",
    "    all_song_id = sorted(dataframes_latents['song_id'].unique())\n",
    "    all_song_id = dict(zip(all_song_id, range(len(all_song_id))))\n",
    "    all_artist_name = sorted(dataframes_latents['artist_name'].unique())\n",
    "    all_artist_name = dict(zip(all_artist_name, range(len(all_artist_name))))\n",
    "    dataframes_latents['ind_msno'] = dataframes_latents['msno'].map(all_msno)\n",
    "    dataframes_latents['ind_song_id'] = dataframes_latents['song_id'].map(all_song_id)\n",
    "    dataframes_latents['ind_artist_name'] = dataframes_latents['artist_name'].map(all_artist_name)\n",
    "\n",
    "    # SVD for msno~song_id\n",
    "    df_copy = dataframes_latents[['msno', 'song_id', 'ind_msno', 'ind_song_id', 'times_song_id']].copy()\n",
    "    mat_song_id = csr_matrix((df_copy['times_song_id'], (df_copy['ind_msno'], df_copy['ind_song_id'])), \n",
    "                              shape=(len(all_msno), len(all_song_id)))\n",
    "    svd_song_id = TruncatedSVD(n_components=20, random_state=0)\n",
    "    svd_song_id.fit(mat_song_id)\n",
    "    svd_song_id.explained_variance_ratio_.sum() \n",
    "    latents_msnos = pd.DataFrame(svd_song_id.transform(mat_song_id))\n",
    "    latents_msnos.columns = ['svd_msno1_'+str(i) for i in range(latents_msnos.shape[1])]\n",
    "    latents_msnos = pd.concat((pd.DataFrame({'msno': all_msno.keys()}), latents_msnos), axis=1)\n",
    "    latents_msnos['msno'] = latents_msnos['msno'].astype('category')\n",
    "    latents_msnos.loc[:, latents_msnos.columns[1:]] = latents_msnos.loc[:, latents_msnos.columns[1:]].astype('float32')\n",
    "    latent_song_id = pd.DataFrame(svd_song_id.components_.T)\n",
    "    latent_song_id.columns = ['svd_song_id_'+str(i) for i in range(latent_song_id.shape[1])]\n",
    "    latent_song_id = pd.concat((pd.DataFrame({'song_id': all_song_id.keys()}), latent_song_id), axis=1)\n",
    "    latent_song_id['song_id'] = latent_song_id['song_id'].astype('category')\n",
    "    latent_song_id.loc[:, latent_song_id.columns[1:]] = latent_song_id.loc[:, latent_song_id.columns[1:]].astype('float32')\n",
    "\n",
    "\n",
    "    del mat_song_id, df_copy\n",
    "    gc.collect()\n",
    "\n",
    "    # SVD for msno~artist_name\n",
    "    mat_artist_name = csr_matrix((dataframes_latents['times_artist_name'], (dataframes_latents['ind_msno'], dataframes_latents['ind_artist_name'])), \n",
    "                                  shape=(len(all_msno), len(all_artist_name)))\n",
    "    svd_artist_name = TruncatedSVD(n_components=10, random_state=0)\n",
    "    svd_artist_name.fit(mat_artist_name)\n",
    "    svd_artist_name.explained_variance_ratio_.sum()\n",
    "    latents_msnos2 = pd.DataFrame(svd_artist_name.transform(mat_artist_name))\n",
    "    latents_msnos2.columns = ['svd_msno2_'+str(i) for i in range(latents_msnos2.shape[1])]\n",
    "    latents_msnos2 = pd.concat((pd.DataFrame({'msno': all_msno.keys()}), latents_msnos2), axis=1)\n",
    "    latents_msnos2['msno'] = latents_msnos2['msno'].astype('category')\n",
    "    latents_msnos2.loc[:, latents_msnos2.columns[1:]] = latents_msnos2.loc[:, latents_msnos2.columns[1:]].astype('float32')\n",
    "    latent_artist_names = pd.DataFrame(svd_artist_name.components_.T)\n",
    "    latent_artist_names.columns = ['svd_artist_name_'+str(i) for i in range(latent_artist_names.shape[1])]\n",
    "    latent_artist_names = pd.concat((pd.DataFrame({'artist_name': all_artist_name.keys()}), latent_artist_names), axis=1)\n",
    "    latent_artist_names['artist_name'] = latent_artist_names['artist_name'].astype('category')\n",
    "    latent_artist_names.loc[:, latent_artist_names.columns[1:]] = latent_artist_names.loc[:, latent_artist_names.columns[1:]].astype('float32')\n",
    "\n",
    "\n",
    "    ### merge all features\n",
    "    dataset = pd.concat((dataset, dataset_profile_msno.loc[:,dataset_profile_msno.columns!='msno']), axis=1)\n",
    "    dataset = pd.concat((dataset, dataframe_profile_song_id.loc[:,dataframe_profile_song_id.columns!='song_id']), axis=1)\n",
    "    dataset = dataset.merge(latents_msnos, how='left', on='msno')\n",
    "    dataset = dataset.merge(latent_song_id, how='left', on='song_id')\n",
    "    dataset = dataset.merge(latents_msnos2, how='left', on='msno')\n",
    "    dataset = dataset.merge(latent_artist_names, how='left', on='artist_name')\n",
    "\n",
    "    del svd_song_id, latents_msnos, latent_song_id, svd_artist_name, latents_msnos2, latent_artist_names\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06f4a9-5450-49bc-ac4c-21098ed7db41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c274c1-ae18-4c50-89ee-ff531d4a9142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
